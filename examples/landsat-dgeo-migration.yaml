name: landsat-dgeo-migration
description: "Migrate Landsat collection to dgeo extension, removing legacy alternates"
version: "1.0"

# Settings
settings:
  logging:
    level: info
    # file: "logs/execution.json"
    output_format: "text"
  resume_from_checkpoint: false

# Pipeline Steps
steps:
  # ============================================================================
  # STEP 1: Ingest - Fetch items from STAC API
  # ============================================================================
  - id: ingest_landsat
    module: IngestModule
    config:
      mode: api
      source: "https://stac.easierdata.info/api/v1/pgstac"
      collection_id: "landsat-c2l1"
      
      # Start with a small test set
      max_items: 10  # Change to null for production run (all items)
      concurrency: 5
      
      # Optional: Filter by date range or bbox
      # datetime: "2023-01-01T00:00:00Z/.."
      # bbox: [-180, -90, 180, 90]

  # ============================================================================
  # STEP 2: Update - Remove legacy IPFS/Filecoin alternate assets
  # ============================================================================
  - id: remove_old_alternates
    module: UpdateModule
    depends_on: [ingest_landsat]
    config:
      # Remove the alternate asset objects containing IPFS and Filecoin
      # Wildcards (*) match all asset keys
      removes:
        - "assets.*.alternate"

  # ============================================================================
  # STEP 3: Extension - Add dgeo extension scaffolding
  # ============================================================================
  - id: add_dgeo_extension
    module: ExtensionModule
    depends_on: [remove_old_alternates]
    config:
      # dgeo extension schema
      schema_uri: "https://raw.githubusercontent.com/DecentralizedGeo/dgeo/refs/heads/main/json-schema/schema.json"
      
      # Include only required fields (prevent None values for optional fields)
      required_fields_only: true
      
      # Set default values
      defaults:
        # Properties-level fields (will be populated by TransformModule)
        # properties.dgeo:cids: []
        # properties.dgeo:piece_cids: []
        
        # Asset-level CID profile defaults (applied to all assets via wildcard)
        assets.*.dgeo:cid_profile.cid_version: 1
        assets.*.dgeo:cid_profile.hash_function: "sha2-256"
        assets.*.dgeo:cid_profile.chunk_algorithm: "fixed"
        assets.*.dgeo:cid_profile.chunk_size: 262144
        assets.*.dgeo:cid_profile.dag_layout: "balanced"

  # ============================================================================
  # STEP 4: Transform - Enrich with extracted asset metadata
  # ============================================================================
  - id: enrich_with_metadata
    module: TransformModule
    depends_on: [add_dgeo_extension]
    config:
      # JSON file generated by: extract_assets_for_dgeo.py convert
      input_file: "./data/landsat/landsat_assets_metadata.json"
      
      # Join on item ID
      input_join_key: "id"
      
      # Merge strategy: keep existing fields, add new ones
      strategy: "merge"
      
      # Log warnings for items missing in metadata file
      handle_missing: "warn"
      
      # Field mapping: source field -> target field in item.properties
      field_mapping:
        # Map extracted CID arrays to dgeo properties
        properties.dgeo:cids: "ipfs_cids"
        properties.dgeo:piece_cids: "filecoin_piece_cids"

  # ============================================================================
  # STEP 5: Transform - Set asset alternates from full metadata
  # ============================================================================
  - id: set_asset_cids
    module: TransformModule
    depends_on: [enrich_with_metadata]
    config:
      # JSON file with full asset metadata (including alternates)
      input_file: "./data/landsat/landsat_assets_full.json"
      
      # Join on item ID
      input_join_key: "item_id"
      
      # Merge strategy: keep existing fields, add new ones (merges dictionaries)
      strategy: "merge"
      
      # Log warnings for items missing in metadata file
      handle_missing: "warn"
      
      # Field mapping using wildcard patterns (applies to ALL assets)
      # Replaces 72 explicit mappings (24 assets Ã— 3 fields) with 3 rules!
      field_mapping:
        # For ALL assets: set alternate field from input data
        # {asset_key} template variable substitutes actual asset name (e.g., "blue", "ANG.txt", etc.)
        assets.*.alternate: 'assets."{asset_key}".alternates'
        
        # For ALL assets: update href to IPFS URL
        assets.*.href: 'assets."{asset_key}".alternates.ipfs.href'
        
        # For ALL assets: update type to match IPFS format
        assets.*.type: 'assets."{asset_key}".alternates.ipfs.type'

  # ============================================================================
  # STEP 6: Update - Set final defaults and timestamps
  # ============================================================================
  - id: set_final_defaults
    module: UpdateModule
    depends_on: [set_asset_cids]
    config:
      # Optional: Set any additional metadata
      updates:
        # Example: Track migration date
        # properties.dgeo:migration_date: "2026-01-28"
        
        # Example: Add custom metadata
        # properties.processing_version: "dgeo-migration-v1"
      
      # Automatically update the 'updated' timestamp
      auto_update_timestamp: true

  # ============================================================================
  # STEP 7: Validate - Check STAC compliance
  # ============================================================================
  # - id: validate_items
  #   module: ValidateModule
  #   depends_on: [set_final_defaults]
  #   config:
  #     # Permissive mode: log warnings but don't fail the pipeline
  #     strict: false
      
  #     # The dgeo extension will be automatically validated
  #     # since it's in the item's stac_extensions array

  # ============================================================================
  # STEP 8: Output - Save migrated items to JSON
  # ============================================================================
  - id: output_json
    module: OutputModule
    # depends_on: [set_final_defaults]
    depends_on: [set_asset_cids]
    config:
      # Output directory
      base_dir: "./outputs/landsat-dgeo-migrated"
      
      # Format: json (individual files) or parquet (single file)
      format: "json"
      
      # Organization: 'collection' (folder per collection) or 'flat' (all in one folder)
      organize_by: "collection"
      
      # Generate a collection.json file
      include_collection: true
      
      # Optional: Set base URL for self links
      # base_url: "https://stac.easierdata.info/api/v1/pgstac"

# ============================================================================
# Post-Pipeline Notes
# ============================================================================
# After running this workflow:
# 
# 1. Review outputs:
#    ls -lh outputs/landsat-dgeo-migrated/landsat-c2l1/
# 
# 2. Verify a sample item:
#    jq '.' outputs/landsat-dgeo-migrated/landsat-c2l1/LC08_L1TP_*.json | head -100
# 
# 3. Check for dgeo extension:
#    jq '.stac_extensions' outputs/landsat-dgeo-migrated/landsat-c2l1/*.json | grep dgeo
# 
# 4. Verify dgeo:cids:
#    jq '.properties["dgeo:cids"]' outputs/landsat-dgeo-migrated/landsat-c2l1/*.json | head
# 
# 5. Check asset-level dgeo:cid:
#    jq '.assets[] | select(.["dgeo:cid"] != null) | .["dgeo:cid"]' \
#       outputs/landsat-dgeo-migrated/landsat-c2l1/*.json | head
# 
# 6. If successful with test set, update max_items to null and re-run for full migration
